{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile #for audio processing\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model , Sequential\n",
    "from keras.utils import Sequence\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['up', 'happy', 'go', 'on', 'one', 'right', 'sheila', 'left', 'eight', 'no', 'zero', 'house', 'off', 'bed', 'wow', 'nine', 'cat', 'stop', 'two', 'tree', 'down', 'bird', 'marvin', 'six', 'seven', 'four', 'three', 'five', 'dog', 'yes']\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/atharva/conversational_robot/assignments/Speech_Recog_Assn/speech_commands_v0.01\")\n",
    "\n",
    "dirs = os.listdir()\n",
    "\n",
    "len_dirs = len(dirs)\n",
    "\n",
    "print(dirs)\n",
    "print(len_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_map_str = \"\"\"\n",
    "<SPACE> 0\n",
    "a 1\n",
    "b 2\n",
    "c 3\n",
    "d 4\n",
    "e 5\n",
    "f 6\n",
    "g 7\n",
    "h 8\n",
    "i 9\n",
    "j 10\n",
    "k 11\n",
    "l 12\n",
    "m 13\n",
    "n 14\n",
    "o 15\n",
    "p 16\n",
    "q 17\n",
    "r 18\n",
    "s 19\n",
    "t 20\n",
    "u 21\n",
    "v 22\n",
    "w 23\n",
    "x 24\n",
    "y 25\n",
    "z 26\n",
    "_ 27\n",
    "\"\"\"\n",
    "\n",
    "char_map = {}\n",
    "index_map = {}\n",
    "\n",
    "for line in char_map_str.strip().split('\\n'):\n",
    "    ch, index = line.split()\n",
    "    if ch == \"<SPACE>\":\n",
    "        ch = \" \"\n",
    "    char_map[ch] = int(index)\n",
    "    index_map[int(index)] = ch\n",
    "\n",
    "index_map[0] = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '_': 27}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total IDs : 64721\n",
      "up/042186b8_nohash_0.wav \n",
      " up/96ab6565_nohash_4.wav\n"
     ]
    }
   ],
   "source": [
    "list_IDs = []\n",
    "\n",
    "for direc in os.listdir():\n",
    "        file = [ f for f in os.listdir(os.getcwd() + '/' + direc ) if f.endswith('.wav')]\n",
    "        for f in file:\n",
    "            list_IDs.append(direc + '/' + f)\n",
    "\n",
    "print(\"Total IDs :\",len(list_IDs))\n",
    "print((list_IDs[0]),\"\\n\",(list_IDs[500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, all_classes, list_IDs, max_label, char_map, total_timedistributed_output = 101, \n",
    "                 batch_size = 40, noise_factor = 0.1 , add_noise = False , normalise = False ,\n",
    "                 dim = (101,1000) ,shuffle = True ):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.all_classes = all_classes\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.noise_factor = noise_factor\n",
    "        self.add_noise = add_noise\n",
    "        self.normalise = normalise\n",
    "        self.max_label = max_label\n",
    "        self.char_map  = char_map\n",
    "        self.total_timedistributed_output = total_timedistributed_output\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        'Denotes the number of batches per epoch'\n",
    "#         return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "        return self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, Y = self.__data_generation(list_IDs_temp)\n",
    "        \n",
    "        input_length = np.array([self.total_timedistributed_output for _ in range(self.batch_size)])\n",
    "        label_length = np.array([self.max_label for _ in range(self.batch_size)])\n",
    "        \n",
    "        inputs = {\"the_inputs\": X, \"the_labels\": Y, \"input_length\":input_length, \"label_length\": label_length}\n",
    "        outputs = {\"ctc\": Y}\n",
    "        return (inputs, outputs)\n",
    "#         return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, 101, 1000 ))\n",
    "        Y = np.empty((self.batch_size , 44 ), dtype=int)\n",
    "        \n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "#             Store sample\n",
    "            \n",
    "#             sample = self.__graph_spectrogram(os.getcwd() + '/' + ID)\n",
    "#             if(sample.shape != self.dim):\n",
    "#                 a = np.zeros(self.dim)\n",
    "#                 a[: , :sample.shape[1]] = sample\n",
    "#                 sample = a    \n",
    "#             if(self.add_noise):\n",
    "#                 sample = self.__add_noise(sample , self.noise_factor)\n",
    "#             if(self.normalise):\n",
    "#                 sample = self.__normalise_spectrogram(sample)\n",
    "#                 \n",
    "#             lab = self.__get_label(ID.split('/')[0] , self.max_label)\n",
    "#                 \n",
    "#             for j in range(0,4):\n",
    "#                 \n",
    "#                 temp_ID = random.choice(list_IDs_temp)\n",
    "#                 \n",
    "#                 temp_sample = self.__graph_spectrogram(os.getcwd() + '/' + temp_ID)\n",
    "#                 if(temp_sample.shape != self.dim):\n",
    "#                     a = np.zeros(self.dim)\n",
    "#                     a[: , :temp_sample.shape[1]] = temp_sample\n",
    "#                     temp_sample = a    \n",
    "#                 if(self.add_noise):\n",
    "#                     temp_sample = self.__add_noise(temp_sample , self.noise_factor)\n",
    "#                 if(self.normalise):\n",
    "#                     temp_sample = self.__normalise_spectrogram(temp_sample)\n",
    "#                 \n",
    "#                 sample = np.append(sample,temp_sample)\n",
    "#                 \n",
    "#                 temp_lab = self.__get_label(temp_ID.split('/')[0] , self.max_label)\n",
    "#                 \n",
    "#                 lab = np.append(lab,27)\n",
    "#                 lab = np.append(lab,temp_lab)\n",
    "\n",
    "            final_samp, final_lab = self.__comb_samples(list_IDs_temp, ID)\n",
    "    \n",
    "            sample = self.__graph_spectrogram(final_samp)\n",
    "#             print(sample.shape)\n",
    "            if(sample.shape != self.dim):\n",
    "                a = np.zeros(self.dim)\n",
    "                a[: , :sample.shape[1]] = sample\n",
    "                sample = a    \n",
    "            if(self.add_noise):\n",
    "                sample = self.__add_noise(sample , self.noise_factor)\n",
    "            if(self.normalise):\n",
    "                sample = self.__normalise_spectrogram(sample)\n",
    "            \n",
    "#             sample = sample.reshape(101,990)\n",
    "            X[i,] = sample\n",
    "\n",
    "            # Store label\n",
    "            Y[i,] = self.__get_label(final_lab , self.max_label)\n",
    "            \n",
    "            os.remove('temp.wav')\n",
    "\n",
    "        return X, Y\n",
    "    \n",
    "    def __comb_samples(self, list_IDs_temp, ID):\n",
    "        samp1 = AudioSegment.from_wav(os.getcwd() + '/' + ID)\n",
    "        comb_sound = samp1\n",
    "        lab = ID.split('/')[0]\n",
    "        for j in range(0,4):\n",
    "            temp_ID = random.choice(list_IDs_temp)\n",
    "            samp2 = AudioSegment.from_wav(os.getcwd() + '/' + temp_ID)\n",
    "            comb_sound = comb_sound + samp2\n",
    "            temp_lab = temp_ID.split('/')[0]   \n",
    "            lab = lab + ' ' + temp_lab\n",
    "\n",
    "        comb_sound.export('temp.wav', format=\"wav\")\n",
    "        return 'temp.wav', lab\n",
    "            \n",
    "        \n",
    "    \n",
    "    def __graph_spectrogram(self, wav_file):\n",
    "        rate, data = self.__get_wav_info(wav_file)\n",
    "        nfft = 200 # Length of each window segment\n",
    "        fs = 8000 # Sampling frequencies\n",
    "        noverlap = 120 # Overlap between windows\n",
    "        nchannels = data.ndim\n",
    "        if nchannels == 1:\n",
    "            pxx, freqs, bins, im = plt.specgram(data, nfft, fs, noverlap = noverlap)\n",
    "        elif nchannels == 2:\n",
    "            pxx, freqs, bins, im = plt.specgram(data[:,0], nfft, fs, noverlap = noverlap)\n",
    "        return pxx\n",
    "\n",
    "    # Load a wav file\n",
    "    def __get_wav_info(self, wav_file):\n",
    "        rate , data = wavfile.read(wav_file)\n",
    "        return rate, data\n",
    "\n",
    "    def __modify_spectrogram_shape(self, sample ,shape = (101,198) ):\n",
    "        a = np.zeros(shape)\n",
    "        a[: , :sample.shape[1]] = sample\n",
    "        return sample\n",
    "\n",
    "    def __add_noise(self, sample , noise_factor):\n",
    "        noise = np.random.randn(sample.shape)\n",
    "        augmented_data = sample + noise_factor * noise\n",
    "        augmented_data = augmented_data.astype(type(sample[0]))\n",
    "        return augmented_data\n",
    "\n",
    "    def __normalise_spectrogram(self, sample):\n",
    "        mean = np.mean(sample, axis=0)\n",
    "        std = np.std(sample, axis=0)\n",
    "        sample = (sample - mean) / std\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def __get_label(self, Y , max_label):\n",
    "        new = [] \n",
    "        for c in Y:\n",
    "            if c not in self.char_map:\n",
    "                continue\n",
    "            elif c == \"_\":\n",
    "                continue\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "                new.append(ch)\n",
    "\n",
    "        while(len(new) < max_label):\n",
    "            new.append(27)\n",
    "        label = np.array(new)\n",
    "\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(dirs ,list_IDs, 44, char_map)\n",
    "# X, Y = training_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-546d2003cf48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "print(X[4].shape)\n",
    "print(Y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "c = np.append(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.merge import Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args    \n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length )    \n",
    "    \n",
    "class CTC():\n",
    "    \"\"\"\n",
    "    Usage:\n",
    "        sr_ctc = CTC(enter input_size and output_size)\n",
    "        sr_ctc.build()\n",
    "        sr_ctc.m.compile()\n",
    "        sr_ctc.tm.compile()\n",
    "    \"\"\"       \n",
    "    def __init__(self,\n",
    "                 input_size=None, \n",
    "                 output_size=None,\n",
    "                 initializer='glorot_uniform'):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.initializer = initializer\n",
    "        self.m = None\n",
    "        self.tm = None\n",
    "                   \n",
    "    def build(self, \n",
    "              conv_filters = 200,\n",
    "              conv2d_filters = 13,\n",
    "              conv_size = 5,\n",
    "              conv2d_strides = 1,\n",
    "              conv_strides = 1,\n",
    "              act = 'relu',\n",
    "              rnn_layers = 2,\n",
    "              LSTM_units = 128,\n",
    "              drop_out = 0.8):\n",
    "           \n",
    "        input_data = Input(shape = self.input_size, name = 'the_inputs')\n",
    "#         x = Conv2D(conv2d_filters,\n",
    "#                    conv_size,\n",
    "#                    strides = (conv2d_strides, conv2d_strides),\n",
    "#                    padding = \"same\",\n",
    "#                    name = \"conv2d1\")(input_data)\n",
    "#         x = BatchNormalization()(x)\n",
    "#         x = Activation(act)(x)\n",
    "#         x = Conv2D(conv2d_filters,\n",
    "#                    conv_size,\n",
    "#                    strides = (conv2d_strides , conv2d_strides),\n",
    "#                    padding = \"same\",\n",
    "#                    name = \"conv2d2\")(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "#         x = Activation(act)(x)\n",
    "#         x = Reshape([606,-1])(x)\n",
    "        x = Conv1D(conv_filters, \n",
    "                   conv_size, \n",
    "                   strides = conv_strides,\n",
    "                   padding = \"same\", \n",
    "                   name = 'conv1d1')(input_data)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(act)(x)\n",
    "        x = Conv1D(conv_filters, \n",
    "                   conv_size, \n",
    "                   strides = conv_strides,\n",
    "                   padding = \"same\", \n",
    "                   name = 'conv1d2')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(act)(x)\n",
    "#         x = Reshape([101])(x)\n",
    "#         x = Dense(23 , activation=\"softmax\", name = \"dense\")(x)\n",
    "#         x = Reshape([23,-1])(x)\n",
    "        for _ in range(rnn_layers):          \n",
    "            x = Bidirectional(LSTM(LSTM_units, \n",
    "                                   return_sequences = True))(x)\n",
    "            x = Dropout(drop_out)(x)\n",
    "            x = BatchNormalization()(x)\n",
    "        y_pred = TimeDistributed(Dense(self.output_size, \n",
    "                                       activation = 'softmax'))(x)        \n",
    "        # ctc inputs\n",
    "        labels = Input(name='the_labels', shape=[None,], dtype='int32')\n",
    "        input_length = Input(name='input_length', shape=[1], dtype='int32')\n",
    "        label_length = Input(name='label_length', shape=[1], dtype='int32')    \n",
    "        # Keras doesn't currently support loss funcs with extra parameters\n",
    "        # so CTC loss is implemented in a lambda layer\n",
    "        loss_out = Lambda(ctc_lambda_func, \n",
    "                          output_shape=(1,), \n",
    "                          name='ctc')([y_pred,\n",
    "                                        labels,\n",
    "                                        input_length,\n",
    "                                        label_length])        \n",
    "        self.tm = Model(inputs = input_data,\n",
    "                        outputs = y_pred)\n",
    "        self.m = Model(inputs = [input_data, \n",
    "                                 labels, \n",
    "                                 input_length, \n",
    "                                 label_length], \n",
    "                        outputs = loss_out)\n",
    "        return self.m, self.tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc(y_true, y_pred):\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<keras.engine.training.Model at 0x7f2c1ed7e978>,\n",
       " <keras.engine.training.Model at 0x7f2c1ed66a58>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ctc = CTC((101,1000), 44)\n",
    "model_ctc.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_inputs (InputLayer)         (None, 101, 1000)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d1 (Conv1D)                (None, 101, 200)     1000200     the_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 101, 200)     800         conv1d1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 101, 200)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d2 (Conv1D)                (None, 101, 200)     200200      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 101, 200)     800         conv1d2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 101, 200)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 101, 256)     336896      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 101, 256)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 101, 256)     1024        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 101, 256)     394240      batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 101, 256)     0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 101, 256)     1024        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 101, 44)      11308       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           time_distributed_1[0][0]         \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,946,492\n",
      "Trainable params: 1,944,668\n",
      "Non-trainable params: 1,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ctc.m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ctc.m.compile(loss = ctc, optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_ctc.m.fit_generator(training_generator, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
